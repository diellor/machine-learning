{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "190ae978",
   "metadata": {},
   "source": [
    "### Introduction and Definition of a Problem\n",
    "This dataset involves a study conducted on patients in Singapore, focusing on their antibody responses to a panel of 214 different immunoreactive antigens. These responses have been measured and recorded, forming the basis of our dataset. The patients in the study are classified into two categories: those who tested positive for melioidosis (87 patients) and those who tested negative for melioidosis (59 patients).\n",
    "\n",
    "Each of the 214 immunoreactive antigens is considered a feature within our dataset. For every patient, there's a set of 214 feature values that represent the person's unique antibody response to each of these antigens. This data can be visualized as a table, where each row corresponds to a patient and each column to an immunoreactive antigen.\n",
    "\n",
    "The task, as a machine learning problem, is to create a model that can accurately predict whether a new patient (not part of the original 146 patients) is likely to test positive or negative for melioidosis based on their antibody responses to these 214 antigens. This is essentially a binary classification problem, where the two classes are \"melioidosis positive\" and \"melioidosis negative\".\n",
    "\n",
    "A successful machine learning model for this task could be an important tool for medical professionals, aiding in the diagnosis of melioidosis. Such a model would take as input the antibody responses to the 214 antigens for a given patient and output a prediction of whether the patient is positive or negative for melioidosis. The goal is to train this model using our current dataset, so that it can make accurate predictions for future, unseen patients.\n",
    "The Algorithm used for classification in this analysis is Bayes Classifier Based on Density Estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de68c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc10fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 215)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data.csv',sep=';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01aa97ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPSS1512</th>\n",
       "      <th>BPSL2520</th>\n",
       "      <th>BPSL2522</th>\n",
       "      <th>BPSS1525</th>\n",
       "      <th>BPSS1516</th>\n",
       "      <th>BPSL2096</th>\n",
       "      <th>BPSS1722</th>\n",
       "      <th>BPSS2141</th>\n",
       "      <th>BPSL2698</th>\n",
       "      <th>BPSS0476</th>\n",
       "      <th>...</th>\n",
       "      <th>BPSS1998</th>\n",
       "      <th>BPSS2277</th>\n",
       "      <th>BPSL0606</th>\n",
       "      <th>BPSS0226</th>\n",
       "      <th>BPSS1401</th>\n",
       "      <th>BPSL0361</th>\n",
       "      <th>BPSS0796.2</th>\n",
       "      <th>BPSS1382</th>\n",
       "      <th>BPSS0412</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>333.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oct.33</td>\n",
       "      <td>162.33</td>\n",
       "      <td>132.33</td>\n",
       "      <td>50.33</td>\n",
       "      <td>64.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135.33</td>\n",
       "      <td>682.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.33</td>\n",
       "      <td>...</td>\n",
       "      <td>146.33</td>\n",
       "      <td>59.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2173.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>534.83</td>\n",
       "      <td>474.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>336.83</td>\n",
       "      <td>0</td>\n",
       "      <td>673.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5558.33</td>\n",
       "      <td>422.33</td>\n",
       "      <td>156.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BPSS1512  BPSL2520  BPSL2522  BPSS1525 BPSS1516  BPSL2096 BPSS1722  \\\n",
       "0        0      0.00      0.00      0.00        0      0.00        0   \n",
       "1   Oct.33    162.33    132.33     50.33    64.33      0.00   135.33   \n",
       "2        0      0.00   2173.33      0.00        0      0.00        0   \n",
       "3        0    534.83    474.83      0.00        0    336.83        0   \n",
       "4  5558.33    422.33    156.33      0.00        0      0.00   108.33   \n",
       "\n",
       "   BPSS2141  BPSL2698  BPSS0476  ... BPSS1998  BPSS2277  BPSL0606  BPSS0226  \\\n",
       "0    333.50       0.0      0.00  ...     0.00         0       0.0       0.0   \n",
       "1    682.33       0.0     13.33  ...   146.33     59.33       0.0       0.0   \n",
       "2      0.00       0.0      0.00  ...     0.00         0       0.0       0.0   \n",
       "3    673.83       0.0      0.00  ...     0.00         0       0.0       0.0   \n",
       "4      0.00       0.0    386.33  ...     0.00         0       0.0       0.0   \n",
       "\n",
       "  BPSS1401 BPSL0361  BPSS0796.2  BPSS1382  BPSS0412 Target  \n",
       "0     0.00      0.0           0       0.0      0.00      0  \n",
       "1     0.00      0.0           0       0.0     60.33      0  \n",
       "2     0.00      0.0           0       0.0      0.00      0  \n",
       "3   126.83      0.0           0       0.0      0.00      0  \n",
       "4     0.00      0.0           0       0.0      0.00      0  \n",
       "\n",
       "[5 rows x 215 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d2b69ea",
   "metadata": {},
   "source": [
    "### Replace all non-numeric values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40b0f2a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPSS1512</th>\n",
       "      <th>BPSL2520</th>\n",
       "      <th>BPSL2522</th>\n",
       "      <th>BPSS1525</th>\n",
       "      <th>BPSS1516</th>\n",
       "      <th>BPSL2096</th>\n",
       "      <th>BPSS1722</th>\n",
       "      <th>BPSS2141</th>\n",
       "      <th>BPSL2698</th>\n",
       "      <th>BPSS0476</th>\n",
       "      <th>...</th>\n",
       "      <th>BPSS1998</th>\n",
       "      <th>BPSS2277</th>\n",
       "      <th>BPSL0606</th>\n",
       "      <th>BPSS0226</th>\n",
       "      <th>BPSS1401</th>\n",
       "      <th>BPSL0361</th>\n",
       "      <th>BPSS0796.2</th>\n",
       "      <th>BPSS1382</th>\n",
       "      <th>BPSS0412</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>333.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>162.33</td>\n",
       "      <td>132.33</td>\n",
       "      <td>50.33</td>\n",
       "      <td>64.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135.33</td>\n",
       "      <td>682.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>...</td>\n",
       "      <td>146.33</td>\n",
       "      <td>59.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2173.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>534.83</td>\n",
       "      <td>474.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>336.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>673.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5558.33</td>\n",
       "      <td>422.33</td>\n",
       "      <td>156.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>386.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5944.33</td>\n",
       "      <td>5807.33</td>\n",
       "      <td>293.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9075.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1061.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>914.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>119.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>347.50</td>\n",
       "      <td>931.50</td>\n",
       "      <td>301.50</td>\n",
       "      <td>253.50</td>\n",
       "      <td>16897.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>442.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8538.50</td>\n",
       "      <td>6528.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2978.50</td>\n",
       "      <td>4600.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3939.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8445.50</td>\n",
       "      <td>1366.50</td>\n",
       "      <td>1472.50</td>\n",
       "      <td>557.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2117.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18714.5</td>\n",
       "      <td>5819.50</td>\n",
       "      <td>3292.5</td>\n",
       "      <td>7271.5</td>\n",
       "      <td>14358.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.00</td>\n",
       "      <td>272.83</td>\n",
       "      <td>787.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>269.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18219.83</td>\n",
       "      <td>18743.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>38097.67</td>\n",
       "      <td>3241.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3176.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BPSS1512  BPSL2520  BPSL2522  BPSS1525  BPSS1516  BPSL2096  BPSS1722  \\\n",
       "0        0.00      0.00      0.00      0.00      0.00      0.00      0.00   \n",
       "1        0.00    162.33    132.33     50.33     64.33      0.00    135.33   \n",
       "2        0.00      0.00   2173.33      0.00      0.00      0.00      0.00   \n",
       "3        0.00    534.83    474.83      0.00      0.00    336.83      0.00   \n",
       "4     5558.33    422.33    156.33      0.00      0.00      0.00    108.33   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "141   5944.33   5807.33    293.33      0.00   9075.33      0.00   1061.33   \n",
       "142    347.50    931.50    301.50    253.50  16897.50      0.00    442.50   \n",
       "143   2978.50   4600.50      0.00      0.00   3939.50      0.00   8445.50   \n",
       "144      0.00    272.83    787.83      0.00      0.00      0.00    269.83   \n",
       "145  38097.67   3241.67      0.00      0.00   3176.67      0.00      0.00   \n",
       "\n",
       "     BPSS2141  BPSL2698  BPSS0476  ...  BPSS1998  BPSS2277  BPSL0606  \\\n",
       "0      333.50      0.00      0.00  ...      0.00      0.00      0.00   \n",
       "1      682.33      0.00     13.33  ...    146.33     59.33      0.00   \n",
       "2        0.00      0.00      0.00  ...      0.00      0.00      0.00   \n",
       "3      673.83      0.00      0.00  ...      0.00      0.00      0.00   \n",
       "4        0.00      0.00    386.33  ...      0.00      0.00      0.00   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "141      0.00      0.00    914.33  ...      0.00      0.00    119.33   \n",
       "142      0.00   8538.50   6528.50  ...      0.00      0.00      0.00   \n",
       "143   1366.50   1472.50    557.50  ...      0.00   2117.50      0.00   \n",
       "144      0.00  18219.83  18743.83  ...      0.00      0.00      0.00   \n",
       "145      0.00      0.00      0.00  ...      0.00      0.00      0.00   \n",
       "\n",
       "     BPSS0226  BPSS1401  BPSL0361  BPSS0796.2  BPSS1382  BPSS0412  Target  \n",
       "0         0.0      0.00       0.0         0.0       0.0      0.00       0  \n",
       "1         0.0      0.00       0.0         0.0       0.0     60.33       0  \n",
       "2         0.0      0.00       0.0         0.0       0.0      0.00       0  \n",
       "3         0.0    126.83       0.0         0.0       0.0      0.00       0  \n",
       "4         0.0      0.00       0.0         0.0       0.0      0.00       0  \n",
       "..        ...       ...       ...         ...       ...       ...     ...  \n",
       "141       0.0      0.00       0.0         0.0       0.0      0.00       1  \n",
       "142       0.0      0.00       0.0         0.0       0.0      0.00       1  \n",
       "143   18714.5   5819.50    3292.5      7271.5   14358.5      0.00       1  \n",
       "144       0.0      0.00       0.0         0.0       0.0      0.00       1  \n",
       "145       0.0      0.00       0.0         0.0       0.0      0.00       1  \n",
       "\n",
       "[146 rows x 215 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = (\n",
    "    pd.to_numeric(data[col],\n",
    "                  errors='coerce')\n",
    "      .fillna(0)\n",
    "    )\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a8ef0a",
   "metadata": {},
   "source": [
    "## Since now we have the data in the right format, we can start with the analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "504bfb1d",
   "metadata": {},
   "source": [
    "First, we prepared training data for both 'infected' and 'noninfected' cases. We used a tool called a kernel density estimator with a Gaussian kernel - this essentially lets us create a model of how the data in each category behaves.\n",
    "\n",
    "Next, we made an educated guess, called a \"prior\", about how likely each category is, just based on how many 'infected' and 'noninfected' cases there are in our training data.\n",
    "\n",
    "When we get new data (we'll call it 'x'), we use our models to estimate how likely 'x' is to belong to each category. This is done using a concept from probability theory called Bayesâ€™ theorem. Here, we consider two factors: our prior guess about how likely each category is, and how typical 'x' is for each category according to our models.\n",
    "\n",
    "We decided to simplify things a bit - just like in a method called NaÃ¯ve Bayes classifier, we dropped a part of the equation that doesn't change between categories.\n",
    "\n",
    "Finally, we put our new data 'x' in the category that seems most probable based on the above. The category with the highest calculated likelihood gets to claim 'x' as one of its own. This way, we have a system for classifying new data points as either 'infected' or 'noninfected'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc6c1b29",
   "metadata": {},
   "source": [
    "### Classification model without using the StandardScaler (without standardization of a data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a97badb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 9, False Positive: 4, True Negative: 14, False Negative: 3\n",
      "Accuracy: 0.7666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/diellor/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KernelDensity was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# separate data into infected and noninfected\n",
    "infected = data[data['Target'] == 1]\n",
    "noninfected = data[data['Target'] == 0]\n",
    "\n",
    "# Train-Test Split\n",
    "train_infected, test_infected = train_test_split(infected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "train_noninfected, test_noninfected = train_test_split(noninfected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# calculate the priors\n",
    "total_train_samples = len(train_infected) + len(train_noninfected)\n",
    "prior_infected = len(train_infected) / total_train_samples\n",
    "prior_noninfected = len(train_noninfected) / total_train_samples\n",
    "\n",
    "# Fit the training data so that we can compute density function for each new input\n",
    "kde_infected = KernelDensity(kernel='gaussian',bandwidth=200.0).fit(train_infected)\n",
    "kde_noninfected = KernelDensity(kernel='gaussian',bandwidth=200.0).fit(train_noninfected)\n",
    "\n",
    "def compute_posterior(x):\n",
    "    log_prior_infected = np.log(prior_infected) + kde_infected.score_samples([x])\n",
    "    log_prior_noninfected = np.log(prior_noninfected) + kde_noninfected.score_samples([x])\n",
    "    return 1 if log_prior_infected > log_prior_noninfected else 0\n",
    "\n",
    "# concatinate to get all test data for both sets\n",
    "X_test = pd.concat([test_infected, test_noninfected])\n",
    "\n",
    "# Create array of true infected and noninfected values\n",
    "y_test = np.concatenate((np.ones(len(test_infected)), np.zeros(len(test_noninfected))))\n",
    "\n",
    "predictions = X_test.apply(compute_posterior, axis=1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"True Positive: {tp}, False Positive: {fp}, True Negative: {tn}, False Negative: {fn}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d9a542e",
   "metadata": {},
   "source": [
    "### Experiment using StarndarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bed163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 11, False Positive: 9, True Negative: 9, False Negative: 1\n",
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "infected = data[data['Target'] == 1]\n",
    "noninfected = data[data['Target'] == 0]\n",
    "\n",
    "train_infected, test_infected = train_test_split(infected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "train_noninfected, test_noninfected = train_test_split(noninfected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a separate scaler for infected and noninfected sets\n",
    "scaler_infected = StandardScaler().fit(train_infected)\n",
    "scaler_noninfected = StandardScaler().fit(train_noninfected)\n",
    "\n",
    "train_infected_norm = scaler_infected.transform(train_infected)\n",
    "train_noninfected_norm = scaler_noninfected.transform(train_noninfected)\n",
    "\n",
    "kde_infected = KernelDensity(kernel='gaussian').fit(train_infected_norm)\n",
    "kde_noninfected = KernelDensity(kernel='gaussian').fit(train_noninfected_norm)\n",
    "\n",
    "total_train_samples = len(train_infected_norm) + len(train_noninfected_norm)\n",
    "prior_infected = len(train_infected_norm) / total_train_samples\n",
    "prior_noninfected = len(train_noninfected_norm) / total_train_samples\n",
    "\n",
    "def compute_posterior(x):\n",
    "    log_prior_infected = np.log(prior_infected) + kde_infected.score_samples([x])\n",
    "    log_prior_noninfected = np.log(prior_noninfected) + kde_noninfected.score_samples([x])\n",
    "    return 1 if log_prior_infected > log_prior_noninfected else 0\n",
    "\n",
    "\n",
    "x_test_infected = scaler_infected.transform(test_infected)\n",
    "x_test_noninfected = scaler_noninfected.transform(test_noninfected)\n",
    "\n",
    "x_test_infected_df = pd.DataFrame(x_test_infected, columns=test_infected.columns)\n",
    "x_test_noninfected_df = pd.DataFrame(x_test_noninfected, columns=test_noninfected.columns)\n",
    "\n",
    "X_test = pd.concat([x_test_infected_df, x_test_noninfected_df])\n",
    "\n",
    "y_test = np.concatenate((np.ones(len(test_infected)), np.zeros(len(test_noninfected))))\n",
    "\n",
    "predictions = []\n",
    "for x in X_test.values:\n",
    "    predictions.append(compute_posterior(x))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"True Positive: {tp}, False Positive: {fp}, True Negative: {tn}, False Negative: {fn}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e27146",
   "metadata": {},
   "source": [
    "### Use GridSearchCV for hyperparameter tuning (this can help us with the accuracy of our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e5713cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Bandwith for train_infected\n",
      "1.0718913192051276\n",
      "Best Bandwith for train_not_infected\n",
      "0.9771241535346497\n",
      "True Positive: 8, False Positive: 4, True Negative: 14, False Negative: 4\n",
      "Accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/Users/diellor/Library/Python/3.10/lib/python/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "infected = data[data['Target'] == 1]\n",
    "noninfected = data[data['Target'] == 0]\n",
    "\n",
    "# Split the data\n",
    "train_infected, test_infected = train_test_split(infected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "train_noninfected, test_noninfected = train_test_split(noninfected.drop('Target',axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_infected = StandardScaler().fit(train_infected)\n",
    "scaler_noninfected = StandardScaler().fit(train_noninfected)\n",
    "\n",
    "train_infected_norm = scaler_infected.transform(train_infected)\n",
    "train_noninfected_norm = scaler_noninfected.transform(train_noninfected)\n",
    "\n",
    "total_train_samples = len(train_infected) + len(train_noninfected)\n",
    "prior_infected = len(train_infected) / total_train_samples\n",
    "prior_noninfected = len(train_noninfected) / total_train_samples\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian')\n",
    "\n",
    "param_grid = {'bandwidth': 10**np.linspace(-2,2,200)}\n",
    "\n",
    "grid = GridSearchCV(kde, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid.fit(train_infected_norm)\n",
    "\n",
    "best_bandwidth = grid.best_params_['bandwidth']\n",
    "print(\"Best Bandwith for train_infected\")\n",
    "print(best_bandwidth)\n",
    "\n",
    "kde_infected = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth).fit(train_infected_norm)\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian')\n",
    "\n",
    "param_grid = {'bandwidth': 10**np.linspace(-2,2,200)}\n",
    "\n",
    "grid = GridSearchCV(kde, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid.fit(train_noninfected_norm)\n",
    "\n",
    "best_bandwidth = grid.best_params_['bandwidth']\n",
    "print(\"Best Bandwith for train_not_infected\")\n",
    "print(best_bandwidth)\n",
    "\n",
    "kde_noninfected = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth).fit(train_noninfected_norm)\n",
    "\n",
    "def compute_posterior(x):\n",
    "    log_prior_infected = np.log(prior_infected) + kde_infected.score_samples([x])\n",
    "    log_prior_noninfected = np.log(prior_noninfected) + kde_noninfected.score_samples([x])\n",
    "    return 1 if log_prior_infected > log_prior_noninfected else 0\n",
    "\n",
    "x_test_infected = scaler_infected.transform(test_infected)\n",
    "x_test_noninfected = scaler_noninfected.transform(test_noninfected)\n",
    "\n",
    "x_test_infected_df = pd.DataFrame(x_test_infected, columns=test_infected.columns)\n",
    "x_test_noninfected_df = pd.DataFrame(x_test_noninfected, columns=test_noninfected.columns)\n",
    "\n",
    "X_test = pd.concat([x_test_infected_df, x_test_noninfected_df])\n",
    "\n",
    "y_test = np.concatenate((np.ones(len(test_infected)), np.zeros(len(test_noninfected))))\n",
    "\n",
    "predictions = []\n",
    "for x in X_test.values:\n",
    "    predictions.append(compute_posterior(x))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"True Positive: {tp}, False Positive: {fp}, True Negative: {tn}, False Negative: {fn}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score']\n",
    "plt.plot(10**np.linspace(-2,2,200), scores)\n",
    "plt.xscale('log')\n",
    "plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54c3cebc",
   "metadata": {},
   "source": [
    "## Summary of our analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96fd2f63",
   "metadata": {},
   "source": [
    "#### Using Gridsearchcv to find the optimal bandwidth didn't help on reaching better accuracy. Still manually trying the best bandwidth was value 3, which gave 0.76 accuraccy with the transformed (scaled) input.\n",
    "#### The first experiment without using stardardscaling performed the best with: True Positive: 9, False Positive: 4, True Negative: 14, False Negative: 3 and Accuracy: 0.76 \n",
    "#### Compared to the second experiment with : True Positive: 9, False Positive: 6, True Negative: 12, False Negative: 3 and Accuracy: 0.7\n",
    "#### While manually switching the bandwidth since gridsearchcv didn't help much, with using bandwidht = 3 for each kernelDensities, results were: True Positive: 10, False Positive: 5, True Negative: 13, False Negative: 2 and with Accuracy: 0.76"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a10f5fa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
